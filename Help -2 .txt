Here is the full implementation of a Spring Boot application to process the JSON response you shared. It maps the JSON data to a model class, converts it into a JPA entity, and persists it into a database using Spring Data JPA.

---

### **1. Define the DTO Model**
This DTO represents the JSON structure.

```java
package com.example.dto;

import com.fasterxml.jackson.annotation.JsonProperty;
import lombok.Data;

import java.util.List;

@Data
public class PipelineDto {
    private String pipelineId;
    private String sourceId;
    private String sourceInstanceId;
    private String effectiveFrom;
    private String effectiveTo;
    private String createdByUser;
    private int version;
    private String pipelineSlaTime;
    private String pipelineSlaTimezone;
    private String feedPeriodScope;
    private String feedContentType;
    private String region;
    private String functionalArea;
    private String feedGroup1;
    private String feedGroup2;
    private String feedGroup3;
    private String feedType;
    private boolean criticalFeed;
    private String businessProcess;
    private String feedSourceGroup;
    private String feedSourceInstanceId;
    private String feedFrequency;
    private String ingestionType;
    private String pipelineDescription;
    private String feedSourceType;
    private Schedule schedule;

    @Data
    public static class Schedule {
        private String frequency;
        private List<Integer> month;
        private List<Integer> monthDay;
        private List<Integer> weekDay;
    }
}
```

---

### **2. Define the JPA Entity**
This entity is mapped to the database.

```java
package com.example.entity;

import jakarta.persistence.*;
import lombok.Data;

import java.util.List;

@Entity
@Data
@Table(name = "pipeline")
public class PipelineEntity {
    @Id
    @GeneratedValue(strategy = GenerationType.IDENTITY)
    private Long id;

    @Column(nullable = false, unique = true)
    private String pipelineId;

    private String sourceId;
    private String sourceInstanceId;
    private String effectiveFrom;
    private String effectiveTo;
    private String createdByUser;
    private int version;
    private String pipelineSlaTime;
    private String pipelineSlaTimezone;
    private String feedPeriodScope;
    private String feedContentType;
    private String region;
    private String functionalArea;
    private String feedGroup1;
    private String feedGroup2;
    private String feedGroup3;
    private String feedType;
    private boolean criticalFeed;
    private String businessProcess;
    private String feedSourceGroup;
    private String feedSourceInstanceId;
    private String feedFrequency;
    private String ingestionType;
    private String pipelineDescription;
    private String feedSourceType;

    @OneToOne(cascade = CascadeType.ALL)
    @JoinColumn(name = "schedule_id", referencedColumnName = "id")
    private ScheduleEntity schedule;
}

@Entity
@Data
@Table(name = "schedule")
class ScheduleEntity {
    @Id
    @GeneratedValue(strategy = GenerationType.IDENTITY)
    private Long id;

    private String frequency;

    @ElementCollection
    @CollectionTable(name = "schedule_months", joinColumns = @JoinColumn(name = "schedule_id"))
    @Column(name = "month")
    private List<Integer> month;

    @ElementCollection
    @CollectionTable(name = "schedule_month_days", joinColumns = @JoinColumn(name = "schedule_id"))
    @Column(name = "month_day")
    private List<Integer> monthDay;

    @ElementCollection
    @CollectionTable(name = "schedule_week_days", joinColumns = @JoinColumn(name = "schedule_id"))
    @Column(name = "week_day")
    private List<Integer> weekDay;
}
```

---

### **3. Create a Mapper to Convert DTO to Entity**
This mapper converts `PipelineDto` to `PipelineEntity`.

```java
package com.example.mapper;

import com.example.dto.PipelineDto;
import com.example.entity.PipelineEntity;
import com.example.entity.ScheduleEntity;
import org.springframework.stereotype.Component;

@Component
public class PipelineMapper {
    public PipelineEntity toEntity(PipelineDto dto) {
        PipelineEntity entity = new PipelineEntity();
        entity.setPipelineId(dto.getPipelineId());
        entity.setSourceId(dto.getSourceId());
        entity.setSourceInstanceId(dto.getSourceInstanceId());
        entity.setEffectiveFrom(dto.getEffectiveFrom());
        entity.setEffectiveTo(dto.getEffectiveTo());
        entity.setCreatedByUser(dto.getCreatedByUser());
        entity.setVersion(dto.getVersion());
        entity.setPipelineSlaTime(dto.getPipelineSlaTime());
        entity.setPipelineSlaTimezone(dto.getPipelineSlaTimezone());
        entity.setFeedPeriodScope(dto.getFeedPeriodScope());
        entity.setFeedContentType(dto.getFeedContentType());
        entity.setRegion(dto.getRegion());
        entity.setFunctionalArea(dto.getFunctionalArea());
        entity.setFeedGroup1(dto.getFeedGroup1());
        entity.setFeedGroup2(dto.getFeedGroup2());
        entity.setFeedGroup3(dto.getFeedGroup3());
        entity.setFeedType(dto.getFeedType());
        entity.setCriticalFeed(dto.isCriticalFeed());
        entity.setBusinessProcess(dto.getBusinessProcess());
        entity.setFeedSourceGroup(dto.getFeedSourceGroup());
        entity.setFeedSourceInstanceId(dto.getFeedSourceInstanceId());
        entity.setFeedFrequency(dto.getFeedFrequency());
        entity.setIngestionType(dto.getIngestionType());
        entity.setPipelineDescription(dto.getPipelineDescription());
        entity.setFeedSourceType(dto.getFeedSourceType());

        if (dto.getSchedule() != null) {
            ScheduleEntity scheduleEntity = new ScheduleEntity();
            scheduleEntity.setFrequency(dto.getSchedule().getFrequency());
            scheduleEntity.setMonth(dto.getSchedule().getMonth());
            scheduleEntity.setMonthDay(dto.getSchedule().getMonthDay());
            scheduleEntity.setWeekDay(dto.getSchedule().getWeekDay());
            entity.setSchedule(scheduleEntity);
        }

        return entity;
    }
}
```

---

### **4. Create the Repository**
This repository handles database operations.

```java
package com.example.repository;

import com.example.entity.PipelineEntity;
import org.springframework.data.jpa.repository.JpaRepository;
import org.springframework.stereotype.Repository;

@Repository
public interface PipelineRepository extends JpaRepository<PipelineEntity, Long> {
}
```

---

### **5. Create the Service Layer**
This service handles business logic.

```java
package com.example.service;

import com.example.dto.PipelineDto;
import com.example.entity.PipelineEntity;
import com.example.mapper.PipelineMapper;
import com.example.repository.PipelineRepository;
import org.springframework.stereotype.Service;

@Service
public class PipelineService {
    private final PipelineRepository repository;
    private final PipelineMapper mapper;

    public PipelineService(PipelineRepository repository, PipelineMapper mapper) {
        this.repository = repository;
        this.mapper = mapper;
    }

    public PipelineEntity savePipeline(PipelineDto dto) {
        PipelineEntity entity = mapper.toEntity(dto);
        return repository.save(entity);
    }
}
```

---

### **6. Create the Controller**
This controller exposes an API to accept JSON and save it to the database.

```java
package com.example.controller;

import com.example.dto.PipelineDto;
import com.example.entity.PipelineEntity;
import com.example.service.PipelineService;
import org.springframework.http.ResponseEntity;
import org.springframework.web.bind.annotation.*;

@RestController
@RequestMapping("/api/pipelines")
public class PipelineController {
    private final PipelineService service;

    public PipelineController(PipelineService service) {
        this.service = service;
    }

    @PostMapping
    public ResponseEntity<PipelineEntity> createPipeline(@RequestBody PipelineDto dto) {
        PipelineEntity savedPipeline = service.savePipeline(dto);
        return ResponseEntity.ok(savedPipeline);
    }
}
```

---

### **7. Configure `application.properties`**
Configure database settings in `src/main/resources/application.properties`.

```properties
spring.datasource.url=jdbc:mysql://localhost:3306/pipelinedb
spring.datasource.username=root
spring.datasource.password=password
spring.datasource.driver-class-name=com.mysql.cj.jdbc.Driver

spring.jpa.database-platform=org.hibernate.dialect.MySQL8Dialect
spring.jpa.hibernate.ddl-auto=update
spring.jpa.show-sql=true
```

---

### **8. Run the Application**
- Start a MySQL database.
- Run the Spring Boot application.
- Use Postman or `curl` to send a JSON request.

---

### **Summary**
- `PipelineDto`: Holds the JSON response data.
- `PipelineEntity`: Represents database table structure.
- `PipelineMapper`: Converts DTO to Entity.
- `PipelineRepository`: Handles database operations.
- `PipelineService`: Business logic layer.
- `PipelineController`: Exposes a REST endpoint.

This implementation properly handles lists of integers and persists them efficiently using Spring Data JPA. Let me know if you need modifications!










&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&


package com.example.entity;

import jakarta.persistence.*;
import lombok.Data;

import java.util.List;

@Entity
@Data
@Table(name = "pipeline")
public class PipelineEntity {
    @Id
    @GeneratedValue(strategy = GenerationType.IDENTITY)
    private Long id;

    @Column(nullable = false, unique = true)
    private String pipelineId;

    private String sourceId;
    private String sourceInstanceId;
    private String effectiveFrom;
    private String effectiveTo;
    private String createdByUser;
    private int version;
    private String pipelineSlaTime;
    private String pipelineSlaTimezone;
    private String feedPeriodScope;
    private String feedContentType;
    private String region;
    private String functionalArea;
    private String feedGroup1;
    private String feedGroup2;
    private String feedGroup3;
    private String feedType;
    private boolean criticalFeed;
    private String businessProcess;
    private String feedSourceGroup;
    private String feedSourceInstanceId;
    private String feedFrequency;
    private String ingestionType;
    private String pipelineDescription;
    private String feedSourceType;

    @OneToOne(cascade = CascadeType.ALL)
    @JoinColumn(name = "schedule_id", referencedColumnName = "id")
    private ScheduleEntity schedule;

    @Entity
    @Data
    @Table(name = "schedule")
    public static class ScheduleEntity {
        @Id
        @GeneratedValue(strategy = GenerationType.IDENTITY)
        private Long id;

        private String frequency;

        @ElementCollection
        @CollectionTable(name = "schedule_months", joinColumns = @JoinColumn(name = "schedule_id"))
        @Column(name = "month")
        private List<Integer> month;

        @ElementCollection
        @CollectionTable(name = "schedule_month_days", joinColumns = @JoinColumn(name = "schedule_id"))
        @Column(name = "month_day")
        private List<Integer> monthDay;

        @ElementCollection
        @CollectionTable(name = "schedule_week_days", joinColumns = @JoinColumn(name = "schedule_id"))
        @Column(name = "week_day")
        private List<Integer> weekDay;
    }
}


ObjectMapper objectMapper = new ObjectMapper();
JsonNode scheduleJson = objectMapper.readTree("{\"frequency\":\"daily\",\"month\":[1,2],\"monthDay\":[1,3],\"weekDay\":[1,5]}");






)))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))


import com.fasterxml.jackson.databind.JsonNode;
import com.fasterxml.jackson.databind.ObjectMapper;
import org.junit.jupiter.api.BeforeEach;
import org.junit.jupiter.api.Test;

import java.sql.Timestamp;
import java.time.LocalTime;

import static org.junit.jupiter.api.Assertions.*;

class DgPipelineConfigTest {

    private DgPipelineConfig config;

    @BeforeEach
    void setUp() {
        config = new DgPipelineConfig();
    }

    @Test
    void testGettersAndSetters() throws Exception {
        config.setPipelineId("123");
        config.setSourceId("source-1");
        config.setSourceInstanceId("instance-1");
        config.setEffectiveFrom(Timestamp.valueOf("2023-03-01 10:15:30.123456"));
        config.setEffectiveTo(Timestamp.valueOf("2023-03-02 11:16:31.123456"));
        config.setCreatedByUser("admin");
        
        ObjectMapper objectMapper = new ObjectMapper();
        JsonNode schedule = objectMapper.readTree("{\"cron\": \"0 0 * * *\"}");
        config.setSchedule(schedule);
        
        config.setVersion(1L);
        config.setPipelineSlaTime(LocalTime.of(12, 30));
        config.setPipelineSlaTimezone("UTC");
        config.setFeedPeriodScope("daily");
        config.setFeedContent("JSON");
        config.setRegion("US");
        config.setFunctionalArea("Finance");
        config.setFirstFeedGroup("Group1");
        config.setSecondFeedGroup("Group2");
        config.setThirdFeedGroup("Group3");
        config.setFeedType("TypeA");
        config.setCriticalFeed(true);
        config.setBusinessProcess("ProcessA");
        config.setFeedSourceGroup("SourceGroup1");
        config.setFeedSourceInstanceId("Instance1");
        config.setFeedFrequency("Hourly");
        config.setIngestionType("Batch");
        config.setPipelineDescription("Test Pipeline");
        config.setFeedSourceType("External");

        assertEquals("123", config.getPipelineId());
        assertEquals("source-1", config.getSourceId());
        assertEquals("instance-1", config.getSourceInstanceId());
        assertEquals(Timestamp.valueOf("2023-03-01 10:15:30.123456"), config.getEffectiveFrom());
        assertEquals(Timestamp.valueOf("2023-03-02 11:16:31.123456"), config.getEffectiveTo());
        assertEquals("admin", config.getCreatedByUser());
        assertEquals(schedule, config.getSchedule());
        assertEquals(1L, config.getVersion());
        assertEquals(LocalTime.of(12, 30), config.getPipelineSlaTime());
        assertEquals("UTC", config.getPipelineSlaTimezone());
        assertEquals("daily", config.getFeedPeriodScope());
        assertEquals("JSON", config.getFeedContent());
        assertEquals("US", config.getRegion());
        assertEquals("Finance", config.getFunctionalArea());
        assertEquals("Group1", config.getFirstFeedGroup());
        assertEquals("Group2", config.getSecondFeedGroup());
        assertEquals("Group3", config.getThirdFeedGroup());
        assertEquals("TypeA", config.getFeedType());
        assertTrue(config.isCriticalFeed());
        assertEquals("ProcessA", config.getBusinessProcess());
        assertEquals("SourceGroup1", config.getFeedSourceGroup());
        assertEquals("Instance1", config.getFeedSourceInstanceId());
        assertEquals("Hourly", config.getFeedFrequency());
        assertEquals("Batch", config.getIngestionType());
        assertEquals("Test Pipeline", config.getPipelineDescription());
        assertEquals("External", config.getFeedSourceType());
    }
}



((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((

import com.fasterxml.jackson.databind.JsonNode;
import org.junit.jupiter.api.Test;
import java.sql.Timestamp;
import java.time.LocalTime;
import static org.junit.jupiter.api.Assertions.*;

class DgPipelineConfigTest {

    @Test
    void testAllArgsConstructor() {
        DgPipelineConfig config = new DgPipelineConfig(
                "123", "source-1", "instance-1",
                Timestamp.valueOf("2023-03-01 10:15:30.123456"),
                Timestamp.valueOf("2023-03-02 11:16:31.123456"),
                "admin", null, 1L, LocalTime.of(12, 30), "UTC",
                "daily", "JSON", "US", "Finance", "Group1", "Group2",
                "Group3", "TypeA", true, "ProcessA", "SourceGroup1",
                "Instance1", "Hourly", "Batch", "Test Pipeline", "External"
        );
        assertNotNull(config);
        assertEquals("123", config.getPipelineId());
    }

    @Test
    void testBuilderPattern() throws Exception {
        ObjectMapper objectMapper = new ObjectMapper();
        JsonNode scheduleJson = objectMapper.readTree("{\"frequency\":\"daily\", \"time\":\"12:00\"}");

        DgPipelineConfig config = DgPipelineConfig.builder()
                .pipelineId("123")
                .sourceId("source-1")
                .sourceInstanceId("instance-1")
                .effectiveFrom(Timestamp.valueOf("2023-03-01 10:15:30.123456"))
                .effectiveTo(Timestamp.valueOf("2023-03-02 11:16:31.123456"))
                .createdByUser("admin")
                .schedule(scheduleJson)  // Testing JsonNode
                .version(1L)
                .pipelineSlaTime(LocalTime.of(12, 30))
                .pipelineSlaTimezone("UTC")
                .feedPeriodScope("daily")
                .feedContent("JSON")
                .region("US")
                .functionalArea("Finance")
                .firstFeedGroup("Group1")
                .secondFeedGroup("Group2")
                .thirdFeedGroup("Group3")
                .feedType("TypeA")
                .criticalFeed(true)
                .businessProcess("ProcessA")
                .feedSourceGroup("SourceGroup1")
                .feedSourceInstanceId("Instance1")
                .feedFrequency("Hourly")
                .ingestionType("Batch")
                .pipelineDescription("Test Pipeline")
                .feedSourceType("External")
                .build();

        assertNotNull(config);
        assertEquals("123", config.getPipelineId());
        assertEquals(scheduleJson, config.getSchedule()); // Validate JsonNode

        // Validate toString()
        String expectedToString = "DgPipelineConfig(pipelineId=123, sourceId=source-1, sourceInstanceId=instance-1, " +
                "effectiveFrom=2023-03-01 10:15:30.123456, effectiveTo=2023-03-02 11:16:31.123456, createdByUser=admin, " +
                "schedule=" + scheduleJson + ", version=1, pipelineSlaTime=12:30, pipelineSlaTimezone=UTC, " +
                "feedPeriodScope=daily, feedContent=JSON, region=US, functionalArea=Finance, firstFeedGroup=Group1, " +
                "secondFeedGroup=Group2, thirdFeedGroup=Group3, feedType=TypeA, criticalFeed=true, businessProcess=ProcessA, " +
                "feedSourceGroup=SourceGroup1, feedSourceInstanceId=Instance1, feedFrequency=Hourly, ingestionType=Batch, " +
                "pipelineDescription=Test Pipeline, feedSourceType=External)";

        assertEquals(expectedToString, config.toString());
    }

    @Test
    void testEqualsMethod() {
        DgPipelineConfig config1 = new DgPipelineConfig("123", "source-1", "instance-1", null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, false, null, null, null, null, null, null, null);
        DgPipelineConfig config2 = new DgPipelineConfig("123", "source-1", "instance-1", null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, false, null, null, null, null, null, null, null);
        DgPipelineConfig config3 = new DgPipelineConfig("456", "source-2", "instance-2", null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, false, null, null, null, null, null, null, null);

        assertEquals(config1, config2); // Same values, should be equal
        assertNotEquals(config1, config3); // Different values, should not be equal
    }

    @Test
    void testHashCodeMethod() {
        DgPipelineConfig config1 = new DgPipelineConfig("123", "source-1", "instance-1", null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, false, null, null, null, null, null, null, null);
        DgPipelineConfig config2 = new DgPipelineConfig("123", "source-1", "instance-1", null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, false, null, null, null, null, null, null, null);
        DgPipelineConfig config3 = new DgPipelineConfig("456", "source-2", "instance-2", null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, false, null, null, null, null, null, null, null);

        assertEquals(config1.hashCode(), config2.hashCode()); // Same values, hashCodes should match
        assertNotEquals(config1.hashCode(), config3.hashCode()); // Different values, different hashCodes
    }

    @Test
    void testToStringMethod() {
        DgPipelineConfig config = new DgPipelineConfig("123", "source-1", "instance-1", null, null, "admin", null, 1L, null, "UTC", "daily", "JSON", "US", "Finance", "Group1", "Group2", "Group3", "TypeA", true, "ProcessA", "SourceGroup1", "Instance1", "Hourly", "Batch", "Test Pipeline", "External");

        String expectedString = "DgPipelineConfig(pipelineId=123, sourceId=source-1, sourceInstanceId=instance-1, effectiveFrom=null, effectiveTo=null, createdByUser=admin, schedule=null, version=1, pipelineSlaTime=null, pipelineSlaTimezone=UTC, feedPeriodScope=daily, feedContent=JSON, region=US, functionalArea=Finance, firstFeedGroup=Group1, secondFeedGroup=Group2, thirdFeedGroup=Group3, feedType=TypeA, criticalFeed=true, businessProcess=ProcessA, feedSourceGroup=SourceGroup1, feedSourceInstanceId=Instance1, feedFrequency=Hourly, ingestionType=Batch, pipelineDescription=Test Pipeline, feedSourceType=External)";
        
        assertEquals(expectedString, config.toString());
    }
}
